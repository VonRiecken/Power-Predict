{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores for 5 folds on the training data: [0.91148104 0.91674235 0.91207561 0.91133013 0.91887947]\n",
      "Mean CV Score: 0.9141017196352784\n",
      "Metrics for Hydro:\n",
      "    Mean CV Score: 0.9141\n",
      "    Mean Absolute Error: 494.8786\n",
      "    Mean Squared Error: 3008284.7158\n",
      "    Root Mean Squared Error: 1734.4408\n",
      "    R-squared: 0.9836\n",
      "\n",
      "\n",
      "Metrics for Solar:\n",
      "    Mean CV Score: 0.9141\n",
      "    Mean Absolute Error: 482.3370\n",
      "    Mean Squared Error: 3339206.0219\n",
      "    Root Mean Squared Error: 1827.3495\n",
      "    R-squared: 0.5645\n",
      "\n",
      "\n",
      "Metrics for Wind:\n",
      "    Mean CV Score: 0.9141\n",
      "    Mean Absolute Error: 708.8939\n",
      "    Mean Squared Error: 7141506.8619\n",
      "    Root Mean Squared Error: 2672.3598\n",
      "    R-squared: 0.7495\n",
      "\n",
      "\n",
      "Metrics for total_sol_wind_hyd:\n",
      "    Mean CV Score: 0.9141\n",
      "    Mean Absolute Error: 1382.5777\n",
      "    Mean Squared Error: 25657803.7841\n",
      "    Root Mean Squared Error: 5065.3533\n",
      "    R-squared: 0.9347\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from power_predict.logic.registry import save_model, save_performance\n",
    "\n",
    "# --- Fetching Data ---\n",
    "df = pd.read_csv('/Users/FernandoSandoval/code/VonRiecken/Power-Predict/power_predict/data/merged_dataset2023-12-04 23:03:28.614514.csv')\n",
    "df.head(5)\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "\n",
    "# Setting Country + Month year as Index\n",
    "df['Country_Month'] = df['Country'] + '_' + df['Month_year'].astype(str)\n",
    "df = df.set_index('Country_Month')\n",
    "\n",
    "# Separating features and target variables\n",
    "X = df.drop(['Unnamed: 0', 'Month_year', 'Balance',\n",
    "             'Combustible_Renewables', 'Hydro', 'Other_Renewables', 'Solar',\n",
    "             'Total_Renewables__Hydro__Geo__Solar__Wind__Other_', 'Wind',\n",
    "             'total_sol_wind_hyd', 'value_CDD_18', 'value_CDD_21',\n",
    "             'value_HDD_16', 'value_HDD_18', 'value_Heat_index',], axis=1)\n",
    "\n",
    "# Applying logistic (log) transformation to the target variables\n",
    "y = np.log1p(df[['Hydro', 'Solar', 'Wind', 'total_sol_wind_hyd']])\n",
    "y\n",
    "\n",
    "# Init list of numerical columns\n",
    "num_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessing_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', MinMaxScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Country'])\n",
    "    ])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Create Model Training ---\n",
    "# KNeighborsRegressor with Polynomial Features wrapped in MultiOutputRegressor\n",
    "polynomial_features = PolynomialFeatures(degree=2)\n",
    "multi_knn_regressor = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=20, p=2, weights='uniform'))\n",
    "\n",
    "# Pipeline including preprocessing, polynomial feature generation, and multi-output Polynomial Regression\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessing_pipeline),\n",
    "    ('poly_features', polynomial_features),\n",
    "    ('multi_knn_regressor', multi_knn_regressor)\n",
    "])\n",
    "\n",
    "\n",
    "# --- 5-Fold Cross-Validation ---\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(f\"Cross-validated scores for 5 folds on the training data: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {mean_cv_score}\")\n",
    "\n",
    "# --- Model Training ---\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)  # X_test will be automatically preprocessed by the pipeline\n",
    "\n",
    "# Inverse log transformation of the predictions\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "# --- Save Model ---\n",
    "    # Save fitted pipeline model as 'knn_log'\n",
    "# save_model(pipeline, 'knn_log')\n",
    "\n",
    "# --- Save Params and Metrics ---\n",
    "    # Save params from fitted pipeline into a dict 'params'\n",
    "params = pipeline.named_steps['multi_knn_regressor'].get_params()\n",
    "\n",
    "# Define performace metrics\n",
    "    # Initialize an empty dictionary to store metrics\n",
    "metrics = {}\n",
    "for i, target in enumerate(['Hydro', 'Solar', 'Wind', 'total_sol_wind_hyd']):\n",
    "    mse = mean_squared_error(np.expm1(y_test.iloc[:, i]), y_pred[:, i])\n",
    "    mae = mean_absolute_error(np.expm1(y_test.iloc[:, i]), y_pred[:, i])\n",
    "    r2 = r2_score(np.expm1(y_test.iloc[:, i]), y_pred[:, i])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Store metrics in the dictionary\n",
    "    metrics[target] = {\n",
    "        'Mean CV Score': mean_cv_score,\n",
    "        'Mean Absolute Error': mae,\n",
    "        'Mean Squared Error': mse,\n",
    "        'Root Mean Squared Error': rmse,\n",
    "        'R-squared': r2\n",
    "    }\n",
    "\n",
    "    # Call save_performace function in registry.py to save dicts with a time stamp in the correct file\n",
    "# save_performance('knn_log', params, metrics)\n",
    "\n",
    "for target, metrics_values in metrics.items():\n",
    "    print(f\"Metrics for {target}:\")\n",
    "    for metric_name, metric_value in metrics_values.items():\n",
    "        print(f\"    {metric_name}: {metric_value:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
